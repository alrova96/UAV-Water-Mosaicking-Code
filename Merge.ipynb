{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG7NoOAOp3eE"
      },
      "source": [
        "# Merge Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OClo_vQp79L"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-4Vb29tqArI"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import traceback\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import warnings\n",
        "import math\n",
        "\n",
        "from contextlib import contextmanager\n",
        "from rasterio.transform import Affine\n",
        "from rasterio.coords import disjoint_bounds\n",
        "from rasterio.enums import Resampling\n",
        "from rasterio import windows"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3a5iYodor8Ut"
      },
      "source": [
        "## Configuration variables\n",
        "Setting Up Config variables such as Dataset, ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ7wdYCnsGEP"
      },
      "outputs": [],
      "source": [
        "PATH_DATASET = '../dataset'\n",
        "PATH_IMAGES = 'images'\n",
        "PATH_RESULT = 'results'\n",
        "SEARCH_CRITERIA = '*.tif'\n",
        "\n",
        "#CSV Header\n",
        "HEADER = ['Coordinate X', 'Coordinate Y', 'Clorophill - a']\n",
        "\n",
        "#Final file names\n",
        "MERGE_OUTNAME = 'merge'\n",
        "\n",
        "#How many rows to write in a CSV file\n",
        "MAX_ROWS_PER_CSV = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gKr5byBvFAr"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaHFWowOrT-Z"
      },
      "source": [
        "### Sum method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivfxb6lJr4U9"
      },
      "outputs": [],
      "source": [
        "def copy_nansum(merged_data, new_data):\n",
        "    \"\"\"Calculates sum between 2 arrays without NaNs\n",
        "\n",
        "    Args:\n",
        "        merged_data : destiny array\n",
        "        new_data : source array\n",
        "    \"\"\"\n",
        "    np.copyto(merged_data, np.nansum(np.array([merged_data, new_data]), axis = 0), casting = \"unsafe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy5XYfdnu1f9"
      },
      "source": [
        "### Raster to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zxfEbFWu47y"
      },
      "outputs": [],
      "source": [
        "def write_value_to_csv(band, lons, lats, writer, width, offset = 0):\n",
        "  \"\"\"Calculates Lat index, Lon index and writes band data based on offset param\n",
        "\n",
        "  Args:\n",
        "      band : Array 1D\n",
        "      lons : Longitudes\n",
        "      lats : Latitudes\n",
        "      writer : CSV writer\n",
        "      width : Matrix width\n",
        "      offset (int, optional): Offest in 1D array. Defaults to 0.\n",
        "  \"\"\"\n",
        "  for i, value in enumerate(band):\n",
        "    x, y = (i + offset) // width, (i + offset) % width\n",
        "    writer.writerow([lons[y], lats[x], value])\n",
        "\n",
        "def band_to_csv(band, transform, filename, max_rows = None):\n",
        "  \"\"\"Writes a band into a CSV file\n",
        "  If max_rows is not None, creates more than one CSV file.\n",
        "\n",
        "  Args:\n",
        "      band : Band 2D \n",
        "      transform : Georeference\n",
        "      filename : Destiny filename\n",
        "      max_rows : Max values to write in a CSV file. Defaults to None.\n",
        "  \"\"\"\n",
        "  height, width = band.shape[0], band.shape[1]\n",
        "  cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
        "  xs, ys = rasterio.transform.xy(transform, rows, cols)\n",
        "  lons, lats = np.array(xs)[0], np.array(ys)[:, 0]\n",
        "  ext = '.csv'\n",
        "  band = np.ravel(band)\n",
        "\n",
        "  if max_rows is None:\n",
        "    with open(filename + ext, 'w', encoding = 'UTF8') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow(HEADER)\n",
        "      write_value_to_csv(band, lons, lats, writer, width)\n",
        "  else:\n",
        "    for i in range( math.ceil((width * height) / max_rows) ):\n",
        "      offset = i * max_rows\n",
        "      with open(filename + str(i) + ext, 'w', encoding = 'UTF8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(HEADER)\n",
        "        write_value_to_csv(band = band[offset : offset + max_rows ], lons = lons, lats = lats, writer = writer, width = width, offset = offset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyF0O26LqgW9"
      },
      "source": [
        "### Merge method based on rasterio.merge.merge()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-EDyG6aqfz7"
      },
      "outputs": [],
      "source": [
        "def merge(\n",
        "    datasets, #Raster data\n",
        "    method = copy_nansum, #Sum method\n",
        "    bounds = None, #Limit if we want to cut the merge\n",
        "    res = None, #Pixel size like 1m, 1km, ...\n",
        "    nodata = None,\n",
        "    dtype = None, #Int, float, ...\n",
        "    precision = None,\n",
        "    indexes = None,\n",
        "    output_count = None,\n",
        "    resampling = Resampling.nearest,\n",
        "    target_aligned_pixels = False,\n",
        "    dst_path = None,\n",
        "    dst_kwds = None,\n",
        "):\n",
        "\n",
        "    # Create a dataset_opener object to use in several places in this function.\n",
        "    if isinstance(datasets[0], (str, os.PathLike)):\n",
        "        dataset_opener = rasterio.open\n",
        "    else:\n",
        "\n",
        "        @contextmanager\n",
        "        def nullcontext(obj):\n",
        "            try:\n",
        "                yield obj\n",
        "            finally:\n",
        "                pass\n",
        "\n",
        "        dataset_opener = nullcontext\n",
        "\n",
        "    with dataset_opener(datasets[0]) as first:\n",
        "        first_profile = first.profile\n",
        "        first_res = first.res\n",
        "        nodataval = first.nodatavals[0]\n",
        "        dt = first.dtypes[0]\n",
        "\n",
        "        if indexes is None:\n",
        "            src_count = first.count\n",
        "        elif isinstance(indexes, int):\n",
        "            src_count = indexes\n",
        "        else:\n",
        "            src_count = len(indexes)\n",
        "\n",
        "        try:\n",
        "            first_colormap = first.colormap(1)\n",
        "        except ValueError:\n",
        "            first_colormap = None\n",
        "\n",
        "    if not output_count:\n",
        "        output_count = src_count\n",
        "\n",
        "    # Extent from option or extent of all inputs\n",
        "    if bounds:\n",
        "        dst_w, dst_s, dst_e, dst_n = bounds\n",
        "    else:\n",
        "        # scan input files\n",
        "        xs = []\n",
        "        ys = []\n",
        "        for dataset in datasets:\n",
        "            with dataset_opener(dataset) as src:\n",
        "                left, bottom, right, top = src.bounds\n",
        "            xs.extend([left, right])\n",
        "            ys.extend([bottom, top])\n",
        "        dst_w, dst_s, dst_e, dst_n = min(xs), min(ys), max(xs), max(ys)\n",
        "\n",
        "    # Resolution/pixel size\n",
        "    if not res:\n",
        "        res = first_res\n",
        "    elif not np.iterable(res):\n",
        "        res = (res, res)\n",
        "    elif len(res) == 1:\n",
        "        res = (res[0], res[0])\n",
        "\n",
        "    if target_aligned_pixels:\n",
        "        dst_w = math.floor(dst_w / res[0]) * res[0]\n",
        "        dst_e = math.ceil(dst_e / res[0]) * res[0]\n",
        "        dst_s = math.floor(dst_s / res[1]) * res[1]\n",
        "        dst_n = math.ceil(dst_n / res[1]) * res[1]\n",
        "\n",
        "    # Compute output array shape. We guarantee it will cover the output\n",
        "    # bounds completely\n",
        "    output_width = int(round((dst_e - dst_w) / res[0]))\n",
        "    output_height = int(round((dst_n - dst_s) / res[1]))\n",
        "\n",
        "    output_transform = Affine.translation(dst_w, dst_n) * Affine.scale(res[0], -res[1])\n",
        "\n",
        "    if dtype is not None:\n",
        "        dt = dtype\n",
        "\n",
        "    out_profile = first_profile\n",
        "    out_profile.update(**(dst_kwds or {}))\n",
        "\n",
        "    out_profile[\"transform\"] = output_transform\n",
        "    out_profile[\"height\"] = output_height\n",
        "    out_profile[\"width\"] = output_width\n",
        "    out_profile[\"count\"] = output_count\n",
        "    out_profile[\"dtype\"] = dt\n",
        "    if nodata is not None:\n",
        "        out_profile[\"nodata\"] = nodata\n",
        "\n",
        "    # create destination array\n",
        "    dest = np.zeros((output_count, output_height, output_width), dtype=dt)\n",
        "    dest_count = np.zeros((output_count, output_height, output_width), dtype=dt)\n",
        "\n",
        "    if nodata is not None:\n",
        "        nodataval = nodata\n",
        "\n",
        "    if nodataval is not None:\n",
        "        # Only fill if the nodataval is within dtype's range\n",
        "        inrange = False\n",
        "        if np.issubdtype(dt, np.integer):\n",
        "            info = np.iinfo(dt)\n",
        "            inrange = (info.min <= nodataval <= info.max)\n",
        "        elif np.issubdtype(dt, np.floating):\n",
        "            if math.isnan(nodataval):\n",
        "                inrange = True\n",
        "            else:\n",
        "                info = np.finfo(dt)\n",
        "                inrange = (info.min <= nodataval <= info.max)\n",
        "        if inrange:\n",
        "            dest.fill(nodataval)\n",
        "        else:\n",
        "            warnings.warn(\n",
        "                \"The nodata value, %s, is beyond the valid \"\n",
        "                \"range of the chosen data type, %s. Consider overriding it \"\n",
        "                \"using the --nodata option for better results.\" % (\n",
        "                    nodataval, dt))\n",
        "    else:\n",
        "        nodataval = 0\n",
        "\n",
        "    for idx, dataset in enumerate(datasets):\n",
        "        with dataset_opener(dataset) as src:\n",
        "            # Real World (tm) use of boundless reads.\n",
        "            # This approach uses the maximum amount of memory to solve the\n",
        "            # problem. Making it more efficient is a TODO.\n",
        "\n",
        "            if disjoint_bounds((dst_w, dst_s, dst_e, dst_n), src.bounds):\n",
        "                continue\n",
        "\n",
        "            # 1. Compute spatial intersection of destination and source\n",
        "            src_w, src_s, src_e, src_n = src.bounds\n",
        "\n",
        "            int_w = src_w if src_w > dst_w else dst_w\n",
        "            int_s = src_s if src_s > dst_s else dst_s\n",
        "            int_e = src_e if src_e < dst_e else dst_e\n",
        "            int_n = src_n if src_n < dst_n else dst_n\n",
        "\n",
        "            # 2. Compute the source window\n",
        "            src_window = windows.from_bounds(int_w, int_s, int_e, int_n, src.transform)\n",
        "\n",
        "            # 3. Compute the destination window\n",
        "            dst_window = windows.from_bounds(\n",
        "                int_w, int_s, int_e, int_n, output_transform\n",
        "            )\n",
        "\n",
        "            # 4. Read data in source window into temp\n",
        "            src_window_rnd_shp = src_window.round_lengths()\n",
        "            dst_window_rnd_shp = dst_window.round_lengths()\n",
        "            dst_window_rnd_off = dst_window_rnd_shp.round_offsets()\n",
        "\n",
        "            temp_height, temp_width = (\n",
        "                dst_window_rnd_off.height,\n",
        "                dst_window_rnd_off.width,\n",
        "            )\n",
        "            temp_shape = (src_count, temp_height, temp_width)\n",
        "\n",
        "            temp_src = src.read(\n",
        "                out_shape=temp_shape,\n",
        "                window=src_window_rnd_shp,\n",
        "                boundless=False,\n",
        "                masked=True,\n",
        "                indexes=indexes,\n",
        "                resampling=resampling,\n",
        "            )\n",
        "\n",
        "        # 5. Copy elements of temp into dest\n",
        "        roff, coff = (max(0, dst_window_rnd_off.row_off), max(0, dst_window_rnd_off.col_off), )\n",
        "\n",
        "        region = dest[:, roff : roff + temp_height, coff : coff + temp_width]\n",
        "        region_count = dest_count[:, roff : roff + temp_height, coff : coff + temp_width]\n",
        "        temp = temp_src[:, : region.shape[1], : region.shape[2]]\n",
        "\n",
        "        method(region, temp)\n",
        "        method(region_count, ~np.isnan(temp))\n",
        "\n",
        "    np.divide(dest, dest_count, out = dest)\n",
        "\n",
        "    if dst_path is None:\n",
        "        return dest, output_transform\n",
        "\n",
        "    else:\n",
        "        with rasterio.open(dst_path, \"w\", **out_profile) as dst:\n",
        "            dst.write(dest)\n",
        "            if first_colormap:\n",
        "                dst.write_colormap(1, first_colormap)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YFPx6uGcsb9p"
      },
      "source": [
        "## Main\n",
        "Notes: \n",
        "The georefence must be always North -> South and West -> East"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p03saUFrsnpW",
        "outputId": "6cc99580-d4df-4525-8a4d-f6efbb4337f6"
      },
      "outputs": [],
      "source": [
        "#Search raster filenames\n",
        "query = os.path.join(PATH_DATASET, PATH_IMAGES, SEARCH_CRITERIA)\n",
        "\n",
        "#Open every raster\n",
        "rasters = [rasterio.open(filename) for filename in glob.glob(query)]\n",
        "\n",
        "try:\n",
        "    #Get merged raster with georeference\n",
        "    merge_data, merge_trans = merge(rasters)\n",
        "\n",
        "    #Save raster in a CSV file\n",
        "    band_to_csv(merge_data[0], merge_trans, os.path.join(PATH_DATASET, PATH_RESULT, MERGE_OUTNAME), MAX_ROWS_PER_CSV)\n",
        "\n",
        "    # Get first raster metadata and modify the necesary data\n",
        "    merge_meta = rasters[0].meta.copy()\n",
        "    merge_meta.update({\"driver\": \"GTiff\", \"height\": merge_data.shape[1], \"width\": merge_data.shape[2], \"transform\": merge_trans,})\n",
        "\n",
        "    #Save raster in a tif file\n",
        "    with rasterio.open(os.path.join(PATH_DATASET, PATH_RESULT, MERGE_OUTNAME, '.tif'), 'w', **merge_meta) as dst:\n",
        "        dst.write(merge_data[0], 1)\n",
        "    \n",
        "except:\n",
        "    traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOv5-Custom-Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "micasense-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "6b4f6751942bbf332d4788baa0260a7c875bb1c123b9fc6e48da792ac05506e9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
